{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse LaTeX file and convert into DeepL-friendly format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input LaTeX source from file and parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " main.arxiv.v3.tex\n"
     ]
    }
   ],
   "source": [
    "from pylatexenc.latexwalker import LatexWalker, LatexCharsNode, LatexEnvironmentNode, LatexMacroNode, LatexSpecialsNode\n",
    "import re\n",
    "\n",
    "input_file = input()\n",
    "with open(input_file) as f:\n",
    "    latex = f.read()\n",
    "w = LatexWalker(latex)\n",
    "(nodelist, pos, len_) = w.get_latex_nodes(pos=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look for \\begin{document} ... \\end{document} environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nodelist = nodelist[-1].nodelist[-1].nodelist[-1].nodelist[-1].nodelist[-1].nodelist[-1].nodelist[-1].nodelist[-1].nodelist[-1].nodelist[-1].nodelist[-1].nodelist ##################################################\n",
    "# nodelist = nodelist[-1].nodeargd.argnlist[-1].nodelist[-1].nodelist[-1].nodeargd.argnlist[-1].nodelist[-1].nodelist[-1].nodeargd.argnlist[-1].nodelist[-1].nodelist[-1].nodelist[-1].nodelist[-1].nodelist[-1].nodelist\n",
    "nodelist = nodelist[-1].nodeargd.argnlist[-1].nodelist[-1].nodelist[-1].nodeargd.argnlist[-1].nodelist[-1].nodelist\n",
    "env = [n for n in nodelist if n.isNodeType(LatexEnvironmentNode)]\n",
    "doc = [e for e in env if e.environmentname=='document']\n",
    "if len(doc)==1:\n",
    "    doc = doc[0]\n",
    "else:\n",
    "    print('Unexpected format with more than one document environment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look for successive LaTeX special expressions and replace them by the format P(pos)L(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "format8 = '{:008}'\n",
    "def replaceSpecial(node):\n",
    "    if node.isNodeType(LatexCharsNode):\n",
    "        s = node.chars\n",
    "    else:\n",
    "        s = ' P'+format8.format(node.pos)+'L'+format8.format(node.len)+' '\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replaceSuccessiveTags(match):\n",
    "    n_space = len(match.group(3))\n",
    "    return 'P'+match.group(1)+'L'+format8.format(int(match.group(2))+int(match.group(4))+n_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnl = doc.nodelist\n",
    "str_list = [replaceSpecial(n) for n in dnl]\n",
    "latex_rep = ''.join(str_list)\n",
    "while re.search('P(\\d{8})L(\\d{8}) ([ \\n]+) P\\d{8}L(\\d{8})', latex_rep) is not None:\n",
    "    latex_rep = re.sub('P(\\d{8})L(\\d{8}) ([ \\n]+) P\\d{8}L(\\d{8})', replaceSuccessiveTags, latex_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the string and translate using DeepL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "paras = re.split('\\n\\n', latex_rep)\n",
    "paras = [p.replace('\\n', ' ') for p in paras]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import pyperclip as ppc\n",
    "\n",
    "options = Options()\n",
    "options.add_argument('--disable-gpu')\n",
    "options.add_argument('--disable-extensions')\n",
    "options.add_argument('--proxy-server=\"direct://\"')\n",
    "options.add_argument('--proxy-bypass-list=*')\n",
    "options.add_argument('--start-maximized')\n",
    "\n",
    "DRIVER_PATH = '/usr/local/bin/chromedriver'\n",
    "driver = webdriver.Chrome(executable_path=DRIVER_PATH, options=options)\n",
    "\n",
    "load_url = 'https://www.deepl.com/ja/translator#en/ja'\n",
    "driver.get(load_url)\n",
    "\n",
    "clipboard = ppc.paste()\n",
    "stextarea = driver.find_element_by_css_selector(\n",
    "    '.lmt__textarea.lmt__source_textarea.lmt__textarea_base_style')\n",
    "ttextarea = driver.find_element_by_css_selector(\n",
    "    '.lmt__textarea.lmt__target_textarea.lmt__textarea_base_style')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translateParagraph(par):\n",
    "    if par == '' or re.fullmatch('[ \\n]+', par) is not None:\n",
    "        return par\n",
    "    ppc.copy(par)\n",
    "    stextarea.send_keys(Keys.COMMAND, 'v')\n",
    "    translated_text = ''\n",
    "    while not translated_text:\n",
    "        time.sleep(1)\n",
    "        translated_text = ttextarea.get_property('value')\n",
    "    stextarea.send_keys(Keys.COMMAND, 'a')\n",
    "    stextarea.send_keys(Keys.BACKSPACE)\n",
    "    return translated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "paras_ja = [translateParagraph(par) for par in paras]\n",
    "latex_ja = '\\n\\n'.join(paras_ja)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppc.copy(clipboard)\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug: comparing original tags and \"translated\" ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def posl2tag(posl):\n",
    "    return 'P'+posl[0]+'L'+posl[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['P00019364L00000003',\n",
       " 'P00010048L00000001',\n",
       " 'P00010087L00000001',\n",
       " 'P00035069L00000001',\n",
       " 'P00010740L00000025',\n",
       " 'P00010083L00000001',\n",
       " 'P00019025L00000002',\n",
       " 'P00011503L00000001',\n",
       " 'P00010739L00000001',\n",
       " 'P00013009L00000067',\n",
       " 'P00011501L00000001',\n",
       " 'P00041743L00000003',\n",
       " 'P00011492L00000006',\n",
       " 'P00010049L00000018',\n",
       " 'P00013091L00000021',\n",
       " 'P00058486L00000027',\n",
       " 'P00058485L00000001',\n",
       " 'P00016277L00000001',\n",
       " 'P00041725L00000012',\n",
       " 'P00010076L00000006',\n",
       " 'P00019047L00000003',\n",
       " 'P00041724L00000001',\n",
       " 'P00019372L00000003',\n",
       " 'P00011504L00000021',\n",
       " 'P00054519L00000002',\n",
       " 'P00013112L00000001',\n",
       " 'P00019109L00000006',\n",
       " 'P00010088L00000020']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = re.compile('P(\\d{8})L(\\d{8})')\n",
    "tag0 = pattern.findall(latex_rep)\n",
    "tag1 = pattern.findall(latex_ja) + re.compile('p(\\d{8})l(\\d{8})').findall(latex_ja)\n",
    "tag_miss = list((set(tag0) ^ set(tag1)) & set(tag0))\n",
    "tag_miss = [posl2tag(t) for t in tag_miss]\n",
    "(tag_miss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = [p for p in paras if tag_miss[0] in p]\n",
    "paras.index(target[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"  P00016521L00000983  P00017504L00000078  P00017582L00000057  P00017639L00000077  P00017716L00000077  P00017793L00000077  P00017870L00000077  P00017947L00000009  P00017956L00000025  We collect blinded data for constraining DM that produces events with  P00018052L00000007  electrons.  We expose the Skipper-CCD for 20 hours, and then read each quadrant through one amplifier with 300 samples per pixel. We refer to one such exposure-and-readout as an  P00018238L00000002 image. P00018246L00000002   We took 22 images of DM science data before a mandatory shutdown. All charge on the CCD is erased before taking a new image.  The read time per sample is 42.825 P00018410L00000001  P00018411L00000005 s, while the readout time of the entire active area is 5.153 P00018476L00000001 hours.  Commissioning data, consisting of (7) 20-hour-exposure images, were used to determine the data quality cuts.   During commissioning,  P00018618L00000002 quadrant-1 P00018630L00000002  and  P00018637L00000002 quadrant-2 P00018649L00000002  showed excellent performance, with a root-mean square noise of 0.146 P00018720L00000003 and 0.139 P00018732L00000003 (with negligible error bars), respectively.   P00018780L00000002 Quadrant-4 P00018792L00000002  had an excessively high charge-transfer-inefficiency (consistent with a disconnected serial register clock) and its data were discarded. In addition,  P00018945L00000002 quadrant-3 P00018957L00000002  (next to quadrant-4 on the short CCD-side), with a noise of 0.142 P00019025L00000002 , had an excess of 1 P00019047L00000003 events in the entire quadrant, but especially in the first  P00019109L00000006 100 columns, consistent with possible blackbody radiation from the surrounding warm vessel leaking onto that part of the cold CCD through the leaf-spring slots (Fig P00019279L00000001  P00019280L00000016 ).  Before unblinding, we thus discarded quadrant-3's data for the 1 P00019364L00000003 and 2 P00019372L00000003 analyses; however, we include its columns 93 to 443 for the 3 P00019436L00000003 and 4 P00019444L00000003 analyses to increase our exposure and since the expected probability of a single spurious 3 P00019538L00000003 event is at the percent level. The total exposure (before cuts) of the DM search data is 19.93 P00019635L00000001 g-day for the 1 P00019651L00000003 and 2 P00019659L00000003 analyses, and 27.82 P00019681L00000001 g-day for the 3 P00019697L00000003 and 4 P00019705L00000003 analyses.\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paras[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  P00016521L00000983 P00017504L00000078 P00017582L00000057 P00017639L00000077 P00017716L00000077 P00017793L00000077 P00017870L00000077 P00017947L00000009 P00017956L00000025 P00018052L00000007電子のイベントを生成するDMを拘束するためのブラインドデータを収集しました。 Skipper-CCDを20時間露光した後、1つのアンプで各象限を300サンプル/ピクセルで読み込みます。このような露光と読み出しを、P00018238L00000002画像と呼びます。P00018246L00000002 DMサイエンスデータを22枚撮影した後、強制的にシャットダウンしました。新しい画像を撮影する前に、CCD上の電荷はすべて消去されます。 1サンプルあたりの読み出し時間は42.825 P00018410L00000001 P00018411L00000005秒、全活動領域の読み出し時間は5.153 P00018476L00000001時間です。 コミッショニング・データは、20時間の露光画像（7枚）で構成され、データ・クオリティ・カットの判定に使用されました。  コミッショニングでは、P00018618L00000002第1象限のP00018630L00000002およびP00018637L00000002第2象限のP00018649L00000002が優れた性能を発揮し、二乗平均平方根ノイズはそれぞれ0.146 P00018720L00000003および0.139 P00018732L00000003（エラー・バーは無視できる程度）となりました。  P00018780L00000002 クワドラント-4 P00018792L00000002は、電荷転送効率が過度に高く（シリアル・レジスタ・クロックの切断と一致）、そのデータは破棄されました。また、P00018945L00000002 クワドラント-3 P00018957L00000002 (ショートCCD側のクワドラント-4の隣)は、ノイズが0. これは、周囲の暖かい容器からの黒体放射が、リーフスプリングの溝を通して冷たいCCDの一部に漏れている可能性があるためです（図P00019279L00000001 P00019280L00000016）。 しかし、3 P00019436L00000003および4 P00019444L00000003の解析では、93～443列目を含めることで、より多くのデータを得ることができました。これは、3 P00019538L00000003の1つのスプリアスイベントの期待される確率がパーセントレベルであるためです。DM検索データの総暴露量（カット前）は、1 P00019651L00000003および2 P00019659L00000003分析では19.93 P00019635L00000001g-day、3 P00019697L00000003および4 P00019705L00000003分析では27.82 P00019681L00000001g-dayです。'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paras_ja[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "warning1 = '\\nLatex2DeepL missing expresion warning: '\n",
    "warning2 = ', '\n",
    "def addMissingExpressionWarning(tag):\n",
    "    target = [p for p in paras if tag in p]\n",
    "    index = paras.index(target[0])\n",
    "    if re.search(warning1, paras_ja[index]) is None:\n",
    "        paras_ja[index] += warning1+'\\\"'+tag+'\\\", '\n",
    "    else:\n",
    "        paras_ja[index] += '\\\"'+tag+'\\\", '\n",
    "for t in tag_miss:\n",
    "    addMissingExpressionWarning(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_ja = '\\n\\n'.join(paras_ja)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace P(pos)L(len) to original LaTeX formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replaceRule(match):\n",
    "    (pos, l) = (int(match.group(1)), int(match.group(2)))\n",
    "    return latex[pos:pos+l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_fin = re.sub('P(\\d{8})L(\\d{8})', replaceRule, latex_ja)\n",
    "latex_fin = re.sub('p(\\d{8})l(\\d{8})', replaceRule, latex_fin) # DeepL sometimes translates P->p and L->l\n",
    "latex_fin = latex[:doc.pos]+'\\\\begin{document}\\n'+latex_fin+'\\n\\\\end{document}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "(head, ext) = re.split('\\.', input_file)\n",
    "output_file = head+'_ja.'+ext\n",
    "with open(output_file, mode='w') as f:\n",
    "    f.write(latex_fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
