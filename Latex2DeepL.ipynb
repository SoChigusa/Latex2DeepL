{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse LaTeX file and convert into DeepL-friendly format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input LaTeX source from file and parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " main.tex\n"
     ]
    }
   ],
   "source": [
    "from pylatexenc.latexwalker import LatexWalker, LatexCharsNode, LatexEnvironmentNode, LatexMacroNode, LatexSpecialsNode\n",
    "import re\n",
    "\n",
    "input_file = input()\n",
    "with open(input_file) as f:\n",
    "    latex = f.read()\n",
    "w = LatexWalker(latex)\n",
    "(nodelist, pos, len_) = w.get_latex_nodes(pos=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look for \\begin{document} ... \\end{document} environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nodelist = nodelist[-1].nodelist[-1].nodelist[-1].nodelist[-1].nodelist[-1].nodelist[-1].nodelist[-1].nodelist[-1].nodelist[-1].nodelist[-1].nodelist[-1].nodelist ##################################################\n",
    "env = [n for n in nodelist if n.isNodeType(LatexEnvironmentNode)]\n",
    "doc = [e for e in env if e.environmentname=='document']\n",
    "if len(doc)==1:\n",
    "    doc = doc[0]\n",
    "else:\n",
    "    print('Unexpected format with more than one document environment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look for successive LaTeX special expressions and replace them by the format P(pos)L(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "format8 = '{:008}'\n",
    "def replaceSpecial(node):\n",
    "    if node.isNodeType(LatexCharsNode):\n",
    "        s = node.chars\n",
    "    else:\n",
    "        s = ' P'+format8.format(node.pos)+'L'+format8.format(node.len)+' '\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replaceSuccessiveTags(match):\n",
    "    n_space = len(match.group(3))\n",
    "    return 'P'+match.group(1)+'L'+format8.format(int(match.group(2))+int(match.group(4))+n_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnl = doc.nodelist\n",
    "str_list = [replaceSpecial(n) for n in dnl]\n",
    "latex_rep = ''.join(str_list)\n",
    "while re.search('P(\\d{8})L(\\d{8}) ([ \\n]+) P\\d{8}L(\\d{8})', latex_rep) is not None:\n",
    "    latex_rep = re.sub('P(\\d{8})L(\\d{8}) ([ \\n]+) P\\d{8}L(\\d{8})', replaceSuccessiveTags, latex_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the string and translate using DeepL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "paras = re.split('\\n\\n', latex_rep)\n",
    "paras = [p.replace('\\n', ' ') for p in paras]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import pyperclip as ppc\n",
    "\n",
    "options = Options()\n",
    "options.add_argument('--disable-gpu')\n",
    "options.add_argument('--disable-extensions')\n",
    "options.add_argument('--proxy-server=\"direct://\"')\n",
    "options.add_argument('--proxy-bypass-list=*')\n",
    "options.add_argument('--start-maximized')\n",
    "\n",
    "DRIVER_PATH = '/usr/local/bin/chromedriver'\n",
    "driver = webdriver.Chrome(executable_path=DRIVER_PATH, options=options)\n",
    "\n",
    "load_url = 'https://www.deepl.com/ja/translator#en/ja'\n",
    "driver.get(load_url)\n",
    "\n",
    "clipboard = ppc.paste()\n",
    "stextarea = driver.find_element_by_css_selector(\n",
    "    '.lmt__textarea.lmt__source_textarea.lmt__textarea_base_style')\n",
    "ttextarea = driver.find_element_by_css_selector(\n",
    "    '.lmt__textarea.lmt__target_textarea.lmt__textarea_base_style')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translateParagraph(par):\n",
    "    if par == '' or par == '\\n':\n",
    "        return par\n",
    "    ppc.copy(par)\n",
    "    stextarea.send_keys(Keys.COMMAND, 'v')\n",
    "    translated_text = ''\n",
    "    while not translated_text:\n",
    "        time.sleep(1)\n",
    "        translated_text = ttextarea.get_property('value')\n",
    "    stextarea.send_keys(Keys.COMMAND, 'a')\n",
    "    stextarea.send_keys(Keys.BACKSPACE)\n",
    "    return translated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "paras_JP = [translateParagraph(par) for par in paras]\n",
    "latex_JP = '\\n\\n'.join(paras_JP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppc.copy(clipboard)\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug: comparing original tags and \"translated\" ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def posl2tag(posl):\n",
    "    return 'P'+posl[0]+'L'+posl[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['P00070168L00000001',\n",
       " 'P00052555L00000021',\n",
       " 'P00077078L00000002',\n",
       " 'P00030331L00000002',\n",
       " 'P00039043L00000002',\n",
       " 'P00016777L00000010',\n",
       " 'P00048629L00000001',\n",
       " 'P00035881L00000002',\n",
       " 'P00002786L00000010',\n",
       " 'P00035951L00000001',\n",
       " 'P00052554L00000001',\n",
       " 'P00016787L00000002',\n",
       " 'P00059033L00000026',\n",
       " 'P00082823L00000001',\n",
       " 'P00069136L00000002',\n",
       " 'P00053870L00000001',\n",
       " 'P00038718L00000023',\n",
       " 'P00048513L00000002',\n",
       " 'P00053871L00000069',\n",
       " 'P00061568L00000008',\n",
       " 'P00071061L00000021',\n",
       " 'P00021427L00000013',\n",
       " 'P00007955L00000026',\n",
       " 'P00069131L00000002',\n",
       " 'P00009047L00000047',\n",
       " 'P00007922L00000010',\n",
       " 'P00076512L00000020',\n",
       " 'P00035952L00000036',\n",
       " 'P00073446L00000002',\n",
       " 'P00070169L00000022',\n",
       " 'P00075930L00000002',\n",
       " 'P00071060L00000001',\n",
       " 'P00071823L00000002']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = re.compile('P(\\d{8})L(\\d{8})')\n",
    "tag0 = pattern.findall(latex_rep)\n",
    "tag1 = pattern.findall(latex_JP) + re.compile('p(\\d{8})l(\\d{8})').findall(latex_JP)\n",
    "tag_miss = list((set(tag0) ^ set(tag1)) & set(tag0))\n",
    "tag_miss = [posl2tag(t) for t in tag_miss]\n",
    "(tag_miss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = [p for p in paras if tag_miss[2] in p]\n",
    "paras.index(target[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  P00076224L00000040  P00076264L00000013 : published results P00076296L00000001  P00076297L00000039  and future projections P00076359L00000001  P00076360L00000020  for both prompt and displaced visible  P00076419L00000024  decays, along with future projections for both prompt and displaced  P00076512L00000020  decays, where the  P00076551L00000008 is produced in the decays of charm mesons P00076600L00000001  P00076601L00000020 . LHCb is a general purpose detector in the forward region, located at the LHC at CERN. It studies heavy flavor physics, including CP violation, rare decays, and new phenomena such as lepton universality violation. LHCb employs real-time calibration, alignment, and physics analysis. During long shutdown 2 (2018 P00076933L00000002 2021) LHCb is moving to a triggerless readout system, in which the full detector information is read out every LHC collision; a data rate of 40 P00077078L00000002 Tb/s. The instantaneous luminosity will increase by a factor of 5, and when combined with the detector upgrades, will greatly increase the sensitivity for many physics channels, including dark photon decays.  P00077288L00000013  P00077301L00000012 : published results for prompt visible  P00077352L00000025  decays P00077384L00000001  P00077385L00000023 . CMS is a large, general purpose detector located at the CERN Large Hadron Collider, which features a 4 P00077512L00000002 T solenoid magnet. CMS has a broad physics program with particular focus on searches for new physics in high transverse momentum processes. The highlight to date has been the discovery, along with ATLAS experiment, of the Higgs boson. The experiment is preparing a number of upgrades to deal with high luminosity LHC running, scheduled to begin in 2026.  P00077868L00000013  P00077881L00000014 : future projections P00077915L00000001  P00077916L00000020  for visible displaced  P00077959L00000008 decays to the  P00077981L00000008 ,  P00077991L00000013 , and  P00078010L00000012  final states. FASER P00078042L00000001  P00078043L00000019  will search for long-lived light particles produced in  P00078118L00000004  collisions at the LHC. It will be located directly on the beam collision axis 480 P00078204L00000002 m from the ATLAS interaction point. The detector consists of a scintillator veto, followed by a 1.5 P00078305L00000002 m decay volume, a 2 P00078326L00000002 m long spectrometer, and a shashlik-style EM calorimeter. The spectrometer has three silicon-strip tracking stations, with three 0.6 P00078460L00000002 T permanent magnet dipoles. Background rates, as confirmed by 2018 emulsion measurements, will be low, and are dominated by high-momentum muons. Data taking will start in 2022.'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paras[91]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  P00076224L00000040 P00076264L00000013 : P00076296L00000001 P00076297L00000039の結果と、P00076359L00000001 P00076360L00000020の結果と、P00076419L00000024の即発と置換された可視光の両方の崩壊についての将来の予測。P00076551L00000008はチャーム中間子P00076600L00000001 P00076601L00000020の崩壊で生成されます。LHCbは，CERNのLHCに設置された前方領域の汎用検出器です。LHCbは，CP対称性の破れ，稀な崩壊，レプトンの普遍性の破れなどの新しい現象を含む，重いフレーバーの物理を研究しています。LHCbでは、リアルタイムでの校正、アライメント、物理解析を行っています。LHCbは、第2期長期停止期間中（2018年P00076933L00000002 2021年）に、トリガーレス読み出しシステムに移行し、LHCの衝突ごとに検出器の全情報を読み出すことになります。瞬間的な輝度は5倍になり，検出器のアップグレードと合わせて，暗黒光子崩壊を含む多くの物理チャンネルの感度が大幅に向上します。 P00077288L00000013 P00077301L00000012 : prompt visible P00077352L00000025 decaysの発表結果 P00077384L00000001 P00077385L00000023 . CMSは、CERNの大型ハドロン衝突型加速器に設置された大型の汎用検出器で、4 P00077512L00000002 Tのソレノイド磁石を備えています。CMSは、高横方向運動量プロセスにおける新物理学の探索に特に重点を置いた、幅広い物理学プログラムを持っています。これまでのハイライトは、ATLAS実験とともにヒッグス粒子を発見したことです。この実験は、2026年に予定されている高輝度LHC運転に対応するために、いくつかのアップグレードを準備しています。 P00077868L00000013 P00077881L00000014 : 将来の予測 P00077915L00000001 P00077916L00000020 目に見える形でのずれ P00077959L00000008 最終状態 P00077981L00000008 , P00077991L00000013 , P00078010L00000012 への崩壊。FASER P00078042L00000001 P00078043L00000019 は、LHC の P00078118L00000004 衝突で生成される長寿命の軽粒子を探索します。この検出器は，ATLAS の相互作用点から 480 P00078204L00000002 m 離れたビーム衝突軸上に設置されます。検出器は、シンチレーターベト、1.5 P00078305L00000002 mのディケイボリューム、2 P00078326L00000002 mのスペクトロメーター、シャシュリックスタイルの電磁カロリメーターで構成されています。分光器にはシリコンストリップのトラッキングステーションが3つあり、0.6 P00078460L00000002 Tの永久磁石ダイポールが3つ付いている。2018年の乳剤測定で確認されたバックグラウンド率は低く、高運動量のミューオンに支配されています。データ取得は2022年に開始される。'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paras_JP[91]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace P(pos)L(len) to original LaTeX formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replaceRule(match):\n",
    "    (pos, l) = (int(match.group(1)), int(match.group(2)))\n",
    "    return latex[pos:pos+l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_fin = re.sub('P(\\d{8})L(\\d{8})', replaceRule, latex_JP)\n",
    "latex_fin = re.sub('p(\\d{8})l(\\d{8})', replaceRule, latex_fin) # DeepL sometimes translates P->p and L->l\n",
    "latex_fin = latex[:doc.pos]+'\\\\begin{document}\\n'+latex_fin+'\\n\\\\end{document}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 're' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b773efd0ebc2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.tex'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'combine_ja.tex'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatex_fin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 're' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "with open('combine_ja.tex', mode='w') as f:\n",
    "    f.write(latex_fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['main', 'tex']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(head, )re.split('\\.', input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
