{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse LaTeX file and convert into DeepL-friendly format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input LaTeX source from file and parse\n",
    "\n",
    "First replace newly defined commands by original commands to help pylatexenc parsing well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def replaceNewCommand(orig_command, match_command):\n",
    "    return orig_command + match_command.group(1)\n",
    "\n",
    "def preprocessing(orig):\n",
    "    mod = orig\n",
    "    while True:\n",
    "        match = re.search(r'\\\\newcommand\\{(.*?)\\}\\{(.*)\\}', mod)\n",
    "        if match is None:\n",
    "            break\n",
    "        mod = mod.replace(match.group(), '')\n",
    "        mod = re.sub(match.group(1).replace('\\\\','\\\\\\\\')+'([\\\\\\\\ \\n\\{\\}\\(\\)\\^\\$_\\+\\-\\*\\/=,.])', lambda wrapper: replaceNewCommand(match.group(2), wrapper), mod)\n",
    "    while True:\n",
    "        match = re.search(r'\\\\def([^\\#\\n]*?)\\{(.*)\\}', mod)\n",
    "        if match is None:\n",
    "            break\n",
    "        mod = mod.replace(match.group(), '')\n",
    "        mod = re.sub(match.group(1).replace('\\\\','\\\\\\\\')+'([\\\\\\\\ \\n\\{\\}\\(\\)\\^\\$_\\+\\-\\*\\/=,.])', lambda wrapper: replaceNewCommand(match.group(2), wrapper), mod)\n",
    "    return mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " v0.tex\n"
     ]
    }
   ],
   "source": [
    "from pylatexenc.latexwalker import LatexWalker, LatexCharsNode, LatexCommentNode, LatexEnvironmentNode, LatexGroupNode, LatexMacroNode, LatexMathNode, LatexSpecialsNode\n",
    "\n",
    "input_file = input()\n",
    "with open(input_file) as f:\n",
    "    latex_orig = f.read()\n",
    "#############################################\n",
    "# latex_mod = preprocessing(latex_orig)\n",
    "latex_mod = latex_orig\n",
    "#############################################\n",
    "w = LatexWalker(latex_mod)\n",
    "(nodelist, pos, len_) = w.get_latex_nodes(pos=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look for \\begin{document} ... \\end{document} environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tempolary: search for the document environment step by step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchDocument(nl):\n",
    "    for i in range(len(nl)):\n",
    "        if nl[i] is None:\n",
    "            continue\n",
    "        if nl[i].isNodeType(LatexEnvironmentNode) and nl[i].environmentname == 'document':\n",
    "            return nl[i]\n",
    "            # return [i]\n",
    "        else:\n",
    "            if nl[i].isNodeType(LatexCharsNode) or nl[i].isNodeType(LatexCommentNode) or nl[i].isNodeType(LatexSpecialsNode):\n",
    "                continue\n",
    "            elif nl[i].isNodeType(LatexMacroNode):\n",
    "                if nl[i].nodeargd is None:\n",
    "                    continue\n",
    "                else:\n",
    "                    next = nl[i].nodeargd.argnlist\n",
    "            else:\n",
    "                next = nl[i].nodelist\n",
    "            res = searchDocument(next)\n",
    "            if res != []:\n",
    "                return res\n",
    "                # return [i,res]\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = searchDocument(nodelist)\n",
    "# env = [n for n in nodelist if n.isNodeType(LatexEnvironmentNode)]\n",
    "# doc = [e for e in env if e.environmentname=='document']\n",
    "# if len(doc)==1:\n",
    "#    doc = doc[0]\n",
    "#else:\n",
    "#    print('Unexpected format with more than one document environment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look for successive LaTeX special expressions and replace them by the format N(from)T(to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replaceSpecial(i, node):\n",
    "    if node.isNodeType(LatexCharsNode):\n",
    "        s = node.chars\n",
    "#    elif node.isNodeType(LatexCommentNode):\n",
    "#        s = ''\n",
    "    elif node.isNodeType(LatexSpecialsNode) and node.specials_chars == '~':\n",
    "        s = ' '\n",
    "    else:\n",
    "        s = ' N'+str(i)+'T'+str(i)+' '\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replaceSuccessiveTags(match):\n",
    "    return 'N'+match.group(1)+'T'+match.group(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnl = doc.nodelist\n",
    "str_list = [replaceSpecial(i, n) for i, n in enumerate(dnl)]\n",
    "latex_rep = ''.join(str_list)\n",
    "while re.search('N\\d+T\\d+ [ \\n]* N\\d+T\\d+', latex_rep) is not None:\n",
    "    latex_rep = re.sub('N(\\d+)T\\d+ [ \\n]* N\\d+T(\\d+)', replaceSuccessiveTags, latex_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the string and translate using DeepL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "paras = re.split('\\n\\n', latex_rep)\n",
    "paras = [p.replace('\\n', ' ') for p in paras]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import pyperclip as ppc\n",
    "\n",
    "options = Options()\n",
    "options.add_argument('--disable-gpu')\n",
    "options.add_argument('--disable-extensions')\n",
    "options.add_argument('--proxy-server=\"direct://\"')\n",
    "options.add_argument('--proxy-bypass-list=*')\n",
    "options.add_argument('--start-maximized')\n",
    "\n",
    "DRIVER_PATH = '/usr/local/bin/chromedriver'\n",
    "driver = webdriver.Chrome(executable_path=DRIVER_PATH, options=options)\n",
    "\n",
    "load_url = 'https://www.deepl.com/ja/translator#en/ja'\n",
    "driver.get(load_url)\n",
    "\n",
    "clipboard = ppc.paste()\n",
    "stextarea = driver.find_element_by_css_selector(\n",
    "    '.lmt__textarea.lmt__source_textarea.lmt__textarea_base_style')\n",
    "ttextarea = driver.find_element_by_css_selector(\n",
    "    '.lmt__textarea.lmt__target_textarea.lmt__textarea_base_style')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translateParagraph(par):\n",
    "    if par == '' or re.fullmatch('[ \\n]+', par) is not None:\n",
    "        return par\n",
    "    ppc.copy(par)\n",
    "    stextarea.send_keys(Keys.COMMAND, 'v')\n",
    "    translated_text = ''\n",
    "    while not translated_text:\n",
    "        time.sleep(1)\n",
    "        translated_text = ttextarea.get_property('value')\n",
    "    stextarea.send_keys(Keys.COMMAND, 'a')\n",
    "    stextarea.send_keys(Keys.BACKSPACE)\n",
    "    return translated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "paras_ja = [translateParagraph(par) for par in paras]\n",
    "latex_ja = '\\n\\n'.join(paras_ja)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppc.copy(clipboard)\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug: comparing original tags and \"translated\" ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def node2tag(node):\n",
    "    return 'N'+node[0]+'T'+node[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['N914T918',\n",
       " 'N1040T1040',\n",
       " 'N942T942',\n",
       " 'N806T806',\n",
       " 'N944T947',\n",
       " 'N664T664',\n",
       " 'N298T301',\n",
       " 'N912T912',\n",
       " 'N122T122',\n",
       " 'N1011T1011',\n",
       " 'N510T510',\n",
       " 'N808T811',\n",
       " 'N910T910',\n",
       " 'N296T296',\n",
       " 'N120T120']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = re.compile('N(\\d+)T(\\d+)')\n",
    "tag0 = pattern.findall(latex_rep)\n",
    "tag1 = pattern.findall(latex_ja) + re.compile('N\\d+T\\d+').findall(latex_ja)\n",
    "tag_miss = list((set(tag0) ^ set(tag1)) & set(tag0))\n",
    "tag_miss = [node2tag(t) for t in tag_miss]\n",
    "(tag_miss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = [p for p in paras if tag_miss[8] in p]\n",
    "paras.index(target[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In Ref.  N108T108 , we revisited the  N110T110  regime, this time lifting the assumption of efficient thermal contact between the dark sector and the SM. We showed that dark sector processes like  N112T112  (hereafter denoted  N114T114 ) and  N116T116  (hereafter denoted  N118T118 ) can generate or remove a significant amount of heat during freezeout; if the energy transfer rate between the SM and the dark sector is not large enough, this can lead to the dark sector kinetically decoupling from the SM before freezeout is complete, leading to a dark sector temperature  N120T120  that is different from the SM temperature  N122T122 . Kinetic decoupling can occur before freezeout is complete for  N124T124  as large as  N126T126  for  N128T128 , dramatically altering how the correct relic abundance is achieved. While some parameter space in the range  N130T130  remains open, especially for  N132T132 , this model still faces strong constraints from limits on the self-interaction cross section of DM, as well as the aforementioned CMB power spectrum. '"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paras[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ref.  N108T108では、N110T110領域を再検討し、今回は暗黒セクターとSMの間の効率的な熱的接触の仮定を解除しました。N112T112（以下、N114T114と表記）やN116T116（以下、N118T118と表記）のような暗黒セクターのプロセスは、フリーズアウト中にかなりの量の熱を生成または除去することができることを示した。N124T124では凍結が完了する前に運動論的デカップリングが起こり、N128T128ではN126T126となり、正しいレリックアバンダンスを得る方法が劇的に変化する。N130T130の範囲では、特にN132T132のパラメータスペースが残っていますが、このモデルはDMの自己相互作用断面積の制限や前述のCMBパワースペクトルによる強い制約を受けています。\\nLatex2DeepL missing expresion warning: \"N122T122\", \"N120T120\", '"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paras_ja[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "warning1 = '\\nLatex2DeepL missing expresion warning: '\n",
    "warning2 = ', '\n",
    "def addMissingExpressionWarning(tag):\n",
    "    target = [p for p in paras if tag in p]\n",
    "    index = paras.index(target[0])\n",
    "    if re.search(warning1, paras_ja[index]) is None:\n",
    "        paras_ja[index] += warning1+'\\\"'+tag+'\\\", '\n",
    "    else:\n",
    "        paras_ja[index] += '\\\"'+tag+'\\\", '\n",
    "for t in tag_miss:\n",
    "    addMissingExpressionWarning(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_ja = '\\n\\n'.join(paras_ja)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace Node#(from)to(to) to original LaTeX formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outputLatex(nl):\n",
    "    latex = ''\n",
    "    if type(nl) is not list:\n",
    "        nl = [nl]\n",
    "    for i in range(len(nl)):\n",
    "        if nl[i] is None:\n",
    "            continue\n",
    "        if nl[i].isNodeType(LatexCharsNode):\n",
    "            latex += nl[i].chars\n",
    "        #elif nl[i].isNodeType(LatexCommentNode):\n",
    "        #    print(nl[i])\n",
    "        elif nl[i].isNodeType(LatexEnvironmentNode):\n",
    "            evn = nl[i].environmentname\n",
    "            latex += '\\\\begin{'+evn+'}'\n",
    "            if nl[i].nodeargd.argnlist != [] and nl[i].nodeargd.argnlist != [None]:  # e.g., \\begin{tabular}{ccc}\n",
    "                latex += outputLatex(nl[i].nodeargd.argnlist)\n",
    "            latex += outputLatex(nl[i].nodelist)\n",
    "            latex += '\\\\end{'+evn+'}'\n",
    "        elif nl[i].isNodeType(LatexGroupNode):\n",
    "            latex += nl[i].delimiters[0]\n",
    "            latex += outputLatex(nl[i].nodelist)\n",
    "            latex += nl[i].delimiters[1]\n",
    "        elif nl[i].isNodeType(LatexMacroNode):\n",
    "            latex += '\\\\'+nl[i].macroname\n",
    "            latex += outputLatex(nl[i].nodeargd.argnlist)\n",
    "            latex += nl[i].macro_post_space\n",
    "        elif nl[i].isNodeType(LatexMathNode):\n",
    "            latex += nl[i].delimiters[0]\n",
    "            latex += outputLatex(nl[i].nodelist)\n",
    "            latex += nl[i].delimiters[1]\n",
    "        elif nl[i].isNodeType(LatexSpecialsNode):\n",
    "            latex += nl[i].specials_chars\n",
    "    return latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replaceRule(match):\n",
    "    (fr, to) = (int(match.group(1)), int(match.group(2)))\n",
    "    return outputLatex(dnl[fr:to+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_fin = re.sub('N(\\d+)T(\\d+)', replaceRule, latex_ja)\n",
    "latex_fin = latex_mod[:doc.pos]+'\\\\begin{document}\\n'+latex_fin+'\\n\\\\end{document}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "(head, ext) = re.split('\\.', input_file)\n",
    "output_file = head+'_ja.'+ext\n",
    "with open(output_file, mode='w') as f:\n",
    "    f.write(latex_fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
