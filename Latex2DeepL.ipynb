{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse LaTeX file and convert into DeepL-friendly format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input LaTeX source from file and parse\n",
    "\n",
    "First replace newly defined commands by original commands to help pylatexenc parsing well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def replaceNewCommand(orig_command, match_command):\n",
    "    return orig_command + match_command.group(1)\n",
    "\n",
    "def preprocessing(orig):\n",
    "    mod = orig\n",
    "    while True:\n",
    "        match = re.search(r'\\\\newcommand\\{(.*?)\\}\\{(.*)\\}', mod)\n",
    "        if match is None:\n",
    "            break\n",
    "        mod = mod.replace(match.group(), '')\n",
    "        mod = re.sub(match.group(1).replace('\\\\','\\\\\\\\')+'([\\\\\\\\ \\n\\{\\}\\(\\)\\^\\$_\\+\\-\\*\\/=,.])', lambda wrapper: replaceNewCommand(match.group(2), wrapper), mod)\n",
    "    while True:\n",
    "        match = re.search(r'\\\\def([^\\#\\n]*?)\\{(.*)\\}', mod)\n",
    "        if match is None:\n",
    "            break\n",
    "        mod = mod.replace(match.group(), '')\n",
    "        mod = re.sub(match.group(1).replace('\\\\','\\\\\\\\')+'([\\\\\\\\ \\n\\{\\}\\(\\)\\^\\$_\\+\\-\\*\\/=,.])', lambda wrapper: replaceNewCommand(match.group(2), wrapper), mod)\n",
    "    return mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outputLatex(of, nl):\n",
    "    latex = ''\n",
    "    if type(nl) is not list:\n",
    "        nl = [nl]\n",
    "    for i in range(len(nl)):\n",
    "        if nl[i] is None:\n",
    "            continue\n",
    "        if nl[i].isNodeType(LatexCharsNode):\n",
    "            latex += nl[i].chars\n",
    "        #elif nl[i].isNodeType(LatexCommentNode):\n",
    "        #    print(nl[i])\n",
    "        elif nl[i].isNodeType(LatexEnvironmentNode):\n",
    "            evn = nl[i].environmentname\n",
    "            latex += '\\\\begin{'+evn+'}'\n",
    "            latex += outputLatex('', nl[i].nodelist)\n",
    "            latex += '\\\\end{'+evn+'}'\n",
    "        elif nl[i].isNodeType(LatexGroupNode):\n",
    "            latex += nl[i].delimiters[0]\n",
    "            latex += outputLatex('', nl[i].nodelist)\n",
    "            latex += nl[i].delimiters[1]\n",
    "        elif nl[i].isNodeType(LatexMacroNode):\n",
    "            latex += '\\\\'+nl[i].macroname\n",
    "            for argn in nl[i].nodeargd.argnlist:\n",
    "                latex += outputLatex('', argn)\n",
    "            latex += nl[i].macro_post_space\n",
    "        elif nl[i].isNodeType(LatexSpecialsNode):\n",
    "            latex += nl[i].specials_chars\n",
    "    if of != '':\n",
    "        with open(of, mode='w') as f:\n",
    "            f.write(latex)\n",
    "    else:\n",
    "        return latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputLatex('test.tex', nodelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylatexenc.latexwalker import LatexWalker, LatexCharsNode, LatexCommentNode, LatexEnvironmentNode, LatexMacroNode, LatexSpecialsNode\n",
    "\n",
    "input_file = input()\n",
    "with open(input_file) as f:\n",
    "    latex_orig = f.read()\n",
    "latex_mod = preprocessing(latex_orig)\n",
    "w = LatexWalker(latex_mod)\n",
    "(nodelist, pos, len_) = w.get_latex_nodes(pos=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look for \\begin{document} ... \\end{document} environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tempolary: search for the document environment step by step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchDocument(nl):\n",
    "    for i in range(len(nl)):\n",
    "        if nl[i] is None:\n",
    "            continue\n",
    "        if nl[i].isNodeType(LatexEnvironmentNode) and nl[i].environmentname == 'document':\n",
    "            return nl[i]\n",
    "            # return [i]\n",
    "        else:\n",
    "            if nl[i].isNodeType(LatexCharsNode) or nl[i].isNodeType(LatexCommentNode) or nl[i].isNodeType(LatexSpecialsNode):\n",
    "                continue\n",
    "            elif nl[i].isNodeType(LatexMacroNode):\n",
    "                if nl[i].nodeargd is None:\n",
    "                    continue\n",
    "                else:\n",
    "                    next = nl[i].nodeargd.argnlist\n",
    "            else:\n",
    "                next = nl[i].nodelist\n",
    "            res = searchDocument(next)\n",
    "            if res != []:\n",
    "                return res\n",
    "                # return [i,res]\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = searchDocument(nodelist)\n",
    "# env = [n for n in nodelist if n.isNodeType(LatexEnvironmentNode)]\n",
    "# doc = [e for e in env if e.environmentname=='document']\n",
    "# if len(doc)==1:\n",
    "#    doc = doc[0]\n",
    "#else:\n",
    "#    print('Unexpected format with more than one document environment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look for successive LaTeX special expressions and replace them by the format P(pos)L(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "format8 = '{:008}'\n",
    "def replaceSpecial(node):\n",
    "    if node.isNodeType(LatexCharsNode):\n",
    "        s = node.chars\n",
    "#    elif node.isNodeType(LatexCommentNode):\n",
    "#        s = ''\n",
    "    elif node.isNodeType(LatexSpecialsNode) and node.specials_chars == '~':\n",
    "        s = ' '\n",
    "    else:\n",
    "        s = ' P'+format8.format(node.pos)+'L'+format8.format(node.len)+' '\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replaceSuccessiveTags(match):\n",
    "    n_space = len(match.group(3))\n",
    "    return 'P'+match.group(1)+'L'+format8.format(int(match.group(2))+int(match.group(4))+n_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnl = doc.nodelist\n",
    "str_list = [replaceSpecial(n) for n in dnl]\n",
    "latex_rep = ''.join(str_list)\n",
    "while re.search('P(\\d{8})L(\\d{8}) ([ \\n]*) P\\d{8}L(\\d{8})', latex_rep) is not None:\n",
    "    latex_rep = re.sub('P(\\d{8})L(\\d{8}) ([ \\n]*) P\\d{8}L(\\d{8})', replaceSuccessiveTags, latex_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the string and translate using DeepL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "paras = re.split('\\n\\n', latex_rep)\n",
    "paras = [p.replace('\\n', ' ') for p in paras]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/81/j4p5hjds6tnd72gqw7pbld140000gn/T/ipykernel_25403/1652354215.py:22: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path=DRIVER_PATH, options=options)\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "import pyperclip as ppc\n",
    "\n",
    "options = Options()\n",
    "options.add_argument('--disable-gpu')\n",
    "options.add_argument('--disable-extensions')\n",
    "options.add_argument('--proxy-server=\"direct://\"')\n",
    "options.add_argument('--proxy-bypass-list=*')\n",
    "options.add_argument('--start-maximized')\n",
    "\n",
    "# automatic driver download\n",
    "# driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "\n",
    "# another choice in case the above fails\n",
    "DRIVER_PATH = '/usr/local/bin/chromedriver'\n",
    "driver = webdriver.Chrome(executable_path=DRIVER_PATH, options=options)\n",
    "\n",
    "load_url = 'https://www.deepl.com/ja/translator#en/ja'\n",
    "driver.get(load_url)\n",
    "\n",
    "clipboard = ppc.paste()\n",
    "stextarea = driver.find_element(By.CSS_SELECTOR, \n",
    "    '.lmt__textarea.lmt__source_textarea.lmt__textarea_base_style')\n",
    "ttextarea = driver.find_element(By.CSS_SELECTOR,\n",
    "    '.lmt__textarea.lmt__target_textarea.lmt__textarea_base_style')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translateParagraph(par):\n",
    "    if par == '' or re.fullmatch('[ \\n]+', par) is not None:\n",
    "        return par\n",
    "    ppc.copy(par)\n",
    "    stextarea.send_keys(Keys.COMMAND, 'v')\n",
    "    translated_text = ''\n",
    "    while not translated_text:\n",
    "        time.sleep(1)\n",
    "        translated_text = ttextarea.get_property('value')\n",
    "    stextarea.send_keys(Keys.COMMAND, 'a')\n",
    "    stextarea.send_keys(Keys.BACKSPACE)\n",
    "    return translated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "paras_ja = [translateParagraph(par) for par in paras]\n",
    "latex_ja = '\\n\\n'.join(paras_ja)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppc.copy(clipboard)\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug: comparing original tags and \"translated\" ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def posl2tag(posl):\n",
    "    return 'P'+posl[0]+'L'+posl[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['P00115137L00000012',\n",
       " 'P00112906L00000199',\n",
       " 'P00011426L00000014',\n",
       " 'P00118645L00000013',\n",
       " 'P00093286L00000012',\n",
       " 'P00076791L00000172',\n",
       " 'P00011334L00000013',\n",
       " 'P00075031L00000257',\n",
       " 'P00116206L00000209',\n",
       " 'P00011315L00000014',\n",
       " 'P00054910L00000022',\n",
       " 'P00056693L00000002',\n",
       " 'P00115154L00000012',\n",
       " 'P00119868L00000015',\n",
       " 'P00075984L00000018',\n",
       " 'P00058652L00000002',\n",
       " 'P00026468L00000003',\n",
       " 'P00068230L00000027',\n",
       " 'P00051495L00000235',\n",
       " 'P00014217L00000047',\n",
       " 'P00053166L00000653',\n",
       " 'P00089891L00000007',\n",
       " 'P00093000L00000012',\n",
       " 'P00011476L00000013',\n",
       " 'P00093244L00000011',\n",
       " 'P00083621L00000003',\n",
       " 'P00079115L00000013',\n",
       " 'P00064152L00000003',\n",
       " 'P00089096L00000008',\n",
       " 'P00074016L00000008',\n",
       " 'P00065987L00000019',\n",
       " 'P00024105L00000029',\n",
       " 'P00037813L00000006',\n",
       " 'P00027807L00000012',\n",
       " 'P00011302L00000010',\n",
       " 'P00074089L00000013',\n",
       " 'P00079059L00000008',\n",
       " 'P00092455L00000444',\n",
       " 'P00023288L00000014',\n",
       " 'P00064253L00000011',\n",
       " 'P00071408L00000011',\n",
       " 'P00058663L00000002',\n",
       " 'P00081262L00000013',\n",
       " 'P00071687L00000011',\n",
       " 'P00079177L00000015',\n",
       " 'P00094917L00000013',\n",
       " 'P00110197L00000015',\n",
       " 'P00076970L00000017',\n",
       " 'P00083602L00000013',\n",
       " 'P00075355L00000003',\n",
       " 'P00055146L00000063',\n",
       " 'P00086970L00000150',\n",
       " 'P00019858L00000004',\n",
       " 'P00071995L00000018',\n",
       " 'P00085288L00000015',\n",
       " 'P00026785L00000014',\n",
       " 'P00090626L00000017',\n",
       " 'P00051357L00000004',\n",
       " 'P00076684L00000020',\n",
       " 'P00028247L00000013',\n",
       " 'P00089790L00000094',\n",
       " 'P00027399L00000017',\n",
       " 'P00088447L00000017',\n",
       " 'P00066018L00000003',\n",
       " 'P00093060L00000012',\n",
       " 'P00063602L00000003',\n",
       " 'P00075447L00000004',\n",
       " 'P00079022L00000003',\n",
       " 'P00101734L00000121',\n",
       " 'P00076992L00000017',\n",
       " 'P00093563L00000012',\n",
       " 'P00081347L00000029',\n",
       " 'P00114791L00000012',\n",
       " 'P00076007L00000018',\n",
       " 'P00104471L00000006',\n",
       " 'P00026016L00000017',\n",
       " 'P00074007L00000004',\n",
       " 'P00066036L00000026',\n",
       " 'P00032729L00000002',\n",
       " 'P00116419L00000133',\n",
       " 'P00075403L00000027',\n",
       " 'P00116139L00000012',\n",
       " 'P00116156L00000012',\n",
       " 'P00113150L00000012',\n",
       " 'P00011921L00000013',\n",
       " 'P00086492L00000018']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = re.compile('P(\\d{8})L(\\d{8})')\n",
    "tag0 = pattern.findall(latex_rep)\n",
    "tag1 = pattern.findall(latex_ja) + re.compile('p(\\d{8})l(\\d{8})').findall(latex_ja)\n",
    "tag_miss = list((set(tag0) ^ set(tag1)) & set(tag0))\n",
    "tag_miss = [posl2tag(t) for t in tag_miss]\n",
    "(tag_miss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = [p for p in paras if tag_miss[0] in p]\n",
    "paras.index(target[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "warning1 = '\\nLatex2DeepL missing expresion warning: '\n",
    "warning2 = ', '\n",
    "def addMissingExpressionWarning(tag):\n",
    "    target = [p for p in paras if tag in p]\n",
    "    index = paras.index(target[0])\n",
    "    if re.search(warning1, paras_ja[index]) is None:\n",
    "        paras_ja[index] += warning1+'\\\"'+tag+'\\\", '\n",
    "    else:\n",
    "        paras_ja[index] += '\\\"'+tag+'\\\", '\n",
    "for t in tag_miss:\n",
    "    addMissingExpressionWarning(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_ja = '\\n\\n'.join(paras_ja)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace P(pos)L(len) to original LaTeX formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replaceRule(match):\n",
    "    (pos, l) = (int(match.group(1)), int(match.group(2)))\n",
    "    return latex_mod[pos:pos+l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_fin = re.sub('P(\\d{8})L(\\d{8})', replaceRule, latex_ja)\n",
    "latex_fin = re.sub('p(\\d{8})l(\\d{8})', replaceRule, latex_fin) # DeepL sometimes translates P->p and L->l\n",
    "latex_fin = latex_mod[:doc.pos]+'\\\\begin{document}\\n'+latex_fin+'\\n\\\\end{document}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "(head, ext) = re.split('\\.', input_file)\n",
    "output_en = head+'_orig.'+ext\n",
    "with open(output_en, mode='w') as f:   # backup of English version with rename\n",
    "    f.write(latex_orig)\n",
    "with open(input_file, mode='w') as f:  # Japanese version with original file name\n",
    "    f.write(latex_fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "6cd6baf3d181ef11cd26fc8374d3027486163e84a235259740ca6dbd6f219356"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
