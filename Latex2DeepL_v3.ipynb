{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse LaTeX file and convert into DeepL-friendly format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse LaTeX and generate tree structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex\n",
    "from anytree import Node, RenderTree\n",
    "\n",
    "env1 = regex.compile(r'\\\\begin\\{((?>[^\\{\\}]+|(?R))*)\\}') # take care of correspondence btw \\{ and \\}\n",
    "env2 = regex.compile(r'\\\\end\\{((?>[^\\{\\}]+|(?R))*)\\}')\n",
    "def latex2tree(latex, tree, texdict, pos=1, structure=[]):\n",
    "    \n",
    "    # initialize tree with input file name\n",
    "    if structure == []:\n",
    "        structure = [tree]\n",
    "    \n",
    "    name = 'n'+str(pos)\n",
    "    match1 = env1.search(latex)\n",
    "    match2 = env2.search(latex)\n",
    "    \n",
    "    # end of document\n",
    "    if match1 is None and match2 is None:\n",
    "        Node(name, parent=structure[-1], dirtype='plain')\n",
    "        texdict[name] = latex\n",
    "    \n",
    "    # end environment\n",
    "    elif match1 is None or match1.span(0)[0] > match2.span(0)[0]:\n",
    "        Node(name, parent=structure[-1], dirtype='plain')\n",
    "        texdict[name] = latex[:match2.span(0)[0]]\n",
    "        \n",
    "        latex = latex[match2.span(0)[1]:]\n",
    "        structure.pop(-1)\n",
    "        latex2tree(latex, tree, texdict, pos+1, structure)\n",
    "        \n",
    "    # begin environment\n",
    "    else:\n",
    "        Node(name, parent=structure[-1], dirtype='plain')\n",
    "        child = Node(match1.group(1), parent=structure[-1], dirtype=match1.group(1))\n",
    "        texdict[name] = latex[:match1.span(0)[0]]\n",
    "        \n",
    "        structure.append(child)\n",
    "        latex = latex[match1.span(0)[1]:]\n",
    "        latex2tree(latex, tree, texdict, pos+1, structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_file = input()\n",
    "input_file = 'reply.tex'\n",
    "with open(input_file) as f:\n",
    "    latex_orig = f.read()\n",
    "    \n",
    "tree = Node(input_file, parent=None)\n",
    "texdict = {}\n",
    "latex2tree(latex_orig, tree, texdict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "children = tree.children[1].children[1].children\n",
    "tlist = [texdict[c.name] if c.dirtype == 'plain' else 'N'+'{:008}'.format(i) for i, c in enumerate(children)]\n",
    "text = ''.join(tlist)\n",
    "paras = regex.split('\\n[\\x20\\t]*\\n', text)\n",
    "paras = [p.replace('\\n', ' ') for p in paras]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reply.tex\n",
      "├── n1\n",
      "├── document\n",
      "│   ├── n2\n",
      "│   ├── enumerate\n",
      "│   │   ├── n3\n",
      "│   │   ├── align*\n",
      "│   │   │   └── n4\n",
      "│   │   └── n5\n",
      "│   ├── n6\n",
      "│   ├── flushleft\n",
      "│   │   └── n7\n",
      "│   └── n8\n",
      "└── n9\n"
     ]
    }
   ],
   "source": [
    "for pre, fill, node in RenderTree(tree):\n",
    "    print('%s%s' % (pre, node.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'plain'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.children[0].dirtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    \\\\item Do the authors have a specific material candidate in mind modelled by the FKMH model?\\n    \\n    The material example of Fe-doped Bismuth Selenide (Li et al, 2010), is not FKMH (to my understanding). In this case the CM axion is a purely longitudinal magnon. The longitudinal case does not have the simple Heisenberg interpretation or Kittel splitting of FKMH.\\n    \\n    Can the present treatment be extended to this case of a longitudinal CM axion?\\n    \\n    \\\\textbf{Reply}:\\n    %%\\n    We agree that the Fe-doped BiSe3 is different from the FKMH model. To our understanding, the axion as the longitudinal magnon in the Fe-doped BiSe3 is not simply expressed by the magnon creation/annihilation operator (at least at the linear level). Thus we think that some extended formalism is required to describe the CM axion in the Fe-doped BiSe3, although we have not found it.\\n    %%\\n    \\n    \\\\item Eq. 5.11 is formally divergent when $m_a=m_m$. Finite linewidth of the magnon regulates this divergence and leads to a Lorentzian resonance.\\n    \\n    Instead the authors consider the approach to steady state up to the axion or magnon coherence time $\\\\tau$. I think a better approach when $Q_m<10^6$ ($Q_m$ is the magnon quality factor) is to integrate over the lineshape (as in a cavity haloscope), while $Q_m >10^6$ (corresponding to $\\\\tau_a < \\\\tau_m$ in 5.16) seems very optimistic.\\n    \\n    I think this is the largest assumption made in the dark matter projection limits and needs far greater justification and discussion.\\n    \\n    Simply put: the authors must justify their choice to take $\\\\tau_m > \\\\tau_a$\\n    \\n    \\\\textbf{Reply}:\\n    %%\\n    First, Eq.(5.11) leads to $a_1(t) \\\\propto t$ for $m_a=m_m$ as shown in (5.12), if one carefully takes the limit $m_m\\\\to m_a$. Thus, there is no divergent behavior in Eq.(5.11) as far as the operation time is finite.\\n    Including a magnon line width through the imaginary part of $m_m$ has the same effect as cutting the time $t$ with the magnon lifetime. Thus the effect of magnon width can be taken into account by considering a general value of $Q=Q_m$.\\n    \\n    The actual value of $Q_m$ is difficult to identify, since we are using a toy model (FKMH model) and there is no real experiment so far in order to measure the magnon width.\\n    In the original draft, $\\\\tau_a < \\\\tau_m$ is assumed just as an illustration of an optimistic setup.\\n    In the revised manuscript we added the results with different choices of the quality factors $Q=10^3$ and $Q=10^4$ in Figs. 1 and 2, which show prospects for more realistic setups.\\n    %%\\n    \\n    \\\\item It is stated that CM axion mixing to the polariton is small. How can this be justified?\\n    \\n    In the Fe-doped Bismuth Selenide case [39] ([41] in the revised draft) the mixing is large, and indeed in [37] ([39] in the revised draft) and in the present work the axion dark matter coupling is driven by this mixing, i.e. via the induced electric field.\\n    \\n    To answer this: For the considered material parameters (CM axion decay constant, magnon mass) what is the effective $b$ parameter and ratio $b/m$ (see \\\\sout{[39]} [41])? If this ratio is small, then indeed the polariton mixing could possibly be neglected at leading order. However, $b/m$ effectively sets the amplitude of the driving term in the current treatment, so it is not clear that small $b/m$ is in any way advantageous.\\n    \\n    Compared to \\\\sout{[37] and [72]} [39] and [74] the present work considers the axion-induced E-field as an external source and ignores the three way mixing axion DM - E-field - CM axion. The neglected mixing affects the dispersion relations, particularly at high applied $B$ field.\\n    \\n    Is considering $E_0$ as a source field consistent in the perturbative expansion?\\n    \\n    The authors should consider this mixing in more detail.\\n    \\n    Going further, this may also need the assumption of uniform $E\\\\cdot B$ to be revised, since finite momentum (and momentum conservation) and material size are important factors in the mixing.  The uniform case considered at present is equivalent to considering only the free space resonance as in \\\\sout{[37]} [39] (see also minor comment below).\\n    \\n    \\\\textbf{Reply}:\\n    %%\\n    For our set up, the $b$ parameter can be evaluated as\\n    '"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texdict['n3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree = Node(input_file, parent=None)\n",
    "# structure = [tree]\n",
    "# texdict = {}\n",
    "# env1 = regex.compile(r'\\\\begin\\{((?>[^\\{\\}]+|(?R))*)\\}') # take care of correspondence btw \\{ and \\}\n",
    "# env2 = regex.compile(r'\\\\end\\{((?>[^\\{\\}]+|(?R))*)\\}')\n",
    "\n",
    "# latex = latex_orig\n",
    "\n",
    "# pos = 1\n",
    "# name = 'n'+str(pos)\n",
    "# match = env1.search(latex)\n",
    "# Node(name, parent=structure[-1])\n",
    "# child = Node('env', parent=tree, dirtype=match.group(1))\n",
    "# structure.append(child)\n",
    "# texdict[name] = latex[:match.span(0)[0]]\n",
    "# latex = latex[match.span(0)[1]:]\n",
    "\n",
    "# pos = pos + 1\n",
    "# name = 'n'+str(pos)\n",
    "# match = env2.search(latex)\n",
    "# Node(name, parent=structure[-1])\n",
    "# structure.pop(-1)\n",
    "# texdict[name] = latex[:match.span(0)[0]]\n",
    "# latex = latex[match.span(0)[1]:]\n",
    "\n",
    "# pos = pos + 1\n",
    "# name = 'n'+str(pos)\n",
    "# match = env1.search(latex)\n",
    "# if match is None:\n",
    "#     Node(name, parent=structure[-1])\n",
    "#     texdict[name] = latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replaceSpecial(i, node):\n",
    "    format8 = '{:008}'\n",
    "    if node is None:\n",
    "        return ''\n",
    "    elif node.isNodeType(LatexCharsNode):\n",
    "        s = node.chars\n",
    "#    elif node.isNodeType(LatexCommentNode):\n",
    "#        s = ''\n",
    "    elif node.isNodeType(LatexSpecialsNode) and node.specials_chars == '~':\n",
    "        s = ' '\n",
    "    else:\n",
    "        s = ' N'+format8.format(i)+'T'+format8.format(i)+' '\n",
    "    return s\n",
    "\n",
    "def replaceSuccessiveTags(match):\n",
    "    return 'N'+match.group(1)+'T'+match.group(2)\n",
    "\n",
    "def replaceTags(dnl):\n",
    "    str_list = [replaceSpecial(i, n) for i, n in enumerate(dnl)]\n",
    "    latex_out = ''.join(str_list)\n",
    "    while regex.search('N\\d{8}T\\d{8} [ \\n]* N\\d{8}T\\d{8}', latex_out) is not None:\n",
    "        latex_out = regex.sub('N(\\d{8})T\\d{8} [ \\n]* N\\d{8}T(\\d{8})', replaceSuccessiveTags, latex_out)\n",
    "    return latex_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import pyperclip as ppc\n",
    "\n",
    "options = Options()\n",
    "options.add_argument('--disable-gpu')\n",
    "options.add_argument('--disable-extensions')\n",
    "options.add_argument('--proxy-server=\"direct://\"')\n",
    "options.add_argument('--proxy-bypass-list=*')\n",
    "options.add_argument('--start-maximized')\n",
    "\n",
    "DRIVER_PATH = '/usr/local/bin/chromedriver'\n",
    "driver = webdriver.Chrome(executable_path=DRIVER_PATH, options=options)\n",
    "\n",
    "load_url = 'https://www.deepl.com/ja/translator#en/ja'\n",
    "driver.get(load_url)\n",
    "\n",
    "clipboard = ppc.paste()\n",
    "stextarea = driver.find_element_by_css_selector(\n",
    "    '.lmt__textarea.lmt__source_textarea.lmt__textarea_base_style')\n",
    "ttextarea = driver.find_element_by_css_selector(\n",
    "    '.lmt__textarea.lmt__target_textarea.lmt__textarea_base_style')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translateParagraph(par):\n",
    "    if par == '' or regex.fullmatch('[ \\n]+', par) is not None:\n",
    "        return par\n",
    "    ppc.copy(par)\n",
    "    stextarea.send_keys(Keys.COMMAND, 'v')\n",
    "    translated_text = ''\n",
    "    while not translated_text:\n",
    "        time.sleep(1)\n",
    "        translated_text = ttextarea.get_property('value')\n",
    "    stextarea.send_keys(Keys.COMMAND, 'a')\n",
    "    stextarea.send_keys(Keys.BACKSPACE)\n",
    "    return translated_text\n",
    "\n",
    "def node2tag(node):\n",
    "    return 'N'+node[0]+'T'+node[1]\n",
    "        \n",
    "def translateOneLevel(doc):\n",
    "    \n",
    "    # translate paragraph by paragraph\n",
    "    if doc.isNodeType(LatexCharsNode) or doc.isNodeType(LatexMacroNode):\n",
    "        dnl = [doc]\n",
    "    else:\n",
    "        dnl = doc.nodelist\n",
    "    latex_rep = replaceTags(dnl)\n",
    "    paras = regex.split('\\n\\n', latex_rep)\n",
    "    paras = [p.replace('\\n', ' ') for p in paras]\n",
    "    paras_ja = [translateParagraph(par) for par in paras]\n",
    "    latex_tmp = '\\n\\n'.join(paras_ja)\n",
    "\n",
    "    # extract missing tag information\n",
    "    pattern = regex.compile('N(\\d{8})T(\\d{8})')\n",
    "    tag0 = pattern.findall(latex_rep)\n",
    "    tag1 = pattern.findall(latex_tmp) + regex.compile('N\\d{8}T\\d{8}').findall(latex_tmp)\n",
    "    tag_miss = list((set(tag0) ^ set(tag1)) & set(tag0))\n",
    "    tag_miss = [node2tag(t) for t in tag_miss]\n",
    "\n",
    "    # add missing expression warning\n",
    "    warning = '\\nLatex2DeepL missing expresion warning: '\n",
    "    for tag in tag_miss:\n",
    "        target = [p for p in paras if tag in p]\n",
    "        index = paras.index(target[0])\n",
    "        if regex.search(warning, paras_ja[index]) is None:\n",
    "            paras_ja[index] += warning+'\\\"'+tag+'\\\", '\n",
    "        else:\n",
    "            paras_ja[index] += '\\\"'+tag+'\\\", '\n",
    "    \n",
    "    # convert back tags into original formula\n",
    "    latex_ja = '\\n\\n'.join(paras_ja)\n",
    "    latex_ja = regex.sub('N(\\d{8})T(\\d{8})', lambda wrapper: replaceRule(dnl, wrapper), latex_ja)\n",
    "    latex_ja = regex.sub('n(\\d{8})t(\\d{8})', lambda wrapper: replaceRule(dnl, wrapper), latex_ja)  # DeepL sometimes translate large characters into small ones\n",
    "    return paras_ja, latex_ja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translateContent(node):\n",
    "#     _, content = translateOneLevel(node)\n",
    "    node.nodelist = [LatexCharsNode(parsing_state=None, pos=0, len=0, chars=content)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translateAllContents(nl):\n",
    "    for i in range(len(nl)):\n",
    "        if nl[i] is None:\n",
    "            continue\n",
    "        if nl[i].isNodeType(LatexEnvironmentNode):\n",
    "            en = nl[i].environmentname\n",
    "            if en == 'abstract' or en == 'itemize' or en == 'enumerate':\n",
    "                translateContent(nl[i])\n",
    "                continue\n",
    "            else:\n",
    "                next = nl[i].nodelist\n",
    "        elif nl[i].isNodeType(LatexMacroNode):\n",
    "            if nl[i].nodeargd is None:\n",
    "                continue\n",
    "            else:\n",
    "                mn = nl[i].macroname\n",
    "                if mn == 'section' or mn == 'subsection' or mn == 'subsubsection' \\\n",
    "                    or mn == 'chapter' or mn == 'subchapter' or mn == 'subsubchapter' or mn == 'footnote' \\\n",
    "                    or mn == 'textit' or mn == 'textbf':\n",
    "                    elem = nl[i].nodeargd.argnlist\n",
    "                    if elem != [] and elem[0] is not None:\n",
    "                        translateContent(elem[0])\n",
    "                    continue\n",
    "                else:\n",
    "                    next = nl[i].nodeargd.argnlist\n",
    "        elif nl[i].isNodeType(LatexCharsNode) or nl[i].isNodeType(LatexCommentNode) or nl[i].isNodeType(LatexSpecialsNode):\n",
    "            continue\n",
    "        else:\n",
    "            next = nl[i].nodelist\n",
    "        translateAllContents(next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylatexenc.latexwalker import LatexWalker, LatexCharsNode, LatexCommentNode, LatexEnvironmentNode, LatexGroupNode, LatexMacroNode, LatexMathNode, LatexSpecialsNode\n",
    "def latexParse(par):\n",
    "    w = LatexWalker(par)\n",
    "    (nodelist, pos, len_) = w.get_latex_nodes(pos=0)\n",
    "    translateAllContents(nodelist)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replaceRule(texdict, match):\n",
    "    (nl, nn) = (match.group(1), match.group(2))\n",
    "    return texdict['L'+nl+'N'+nn]\n",
    "\n",
    "def translateTree(tree, texdict, layer=1, doc=False):\n",
    "    children = tree.children\n",
    "    llist = [texdict[c.name] if c.dirtype == 'plain' else 'L'+str(layer)+'N'+'{:008}'.format(i) for i, c in enumerate(children)]\n",
    "    latex = ''.join(llist)\n",
    "    \n",
    "    # translate at any level inside document environment\n",
    "    if doc:\n",
    "        paras = regex.split('\\n[\\x20\\t]*\\n', latex)\n",
    "        paras = [p.replace('\\n', ' ') for p in paras]\n",
    "        \n",
    "        # translate each paragraph here\n",
    "        paras_ja = paras\n",
    "        print(paras)\n",
    "        [latexParse(p) for p in paras_ja]\n",
    "#         paras_ja = [translateParagraph(p) for p in paras]\n",
    "        \n",
    "        latex_ja = '\\n\\n'.join(paras_ja)\n",
    "    \n",
    "    # do not translate outside document\n",
    "    else:\n",
    "        latex_ja = latex\n",
    "\n",
    "    # go to next level\n",
    "    for i, c in enumerate(children):\n",
    "        if c.children != ():\n",
    "            texdict['L'+str(layer)+'N'+'{:008}'.format(i)] = translateTree(c, texdict, layer+1, True)\n",
    "            \n",
    "    # convert back tags into original formula\n",
    "    latex_ja = regex.sub('L(\\d)N(\\d{8})', lambda wrapper: replaceRule(texdict, wrapper), latex_ja)\n",
    "    latex_ja = regex.sub('l(\\d)n(\\d{8})', lambda wrapper: replaceRule(texdict, wrapper), latex_ja)  # DeepL sometimes translate tags in this form\n",
    "    \n",
    "    return latex_ja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'We thank the referee very much for careful reading and useful comments that help to improve our draft. Replies to the comments are listed below.', 'L2N00000001', ' We hope that the modified version is suitable for publication in JHEP.\\\\\\\\', 'Sincerely,\\\\\\\\', 'L2N00000003', ' ']\n",
      "['     \\\\item Do the authors have a specific material candidate in mind modelled by the FKMH model?', '    The material example of Fe-doped Bismuth Selenide (Li et al, 2010), is not FKMH (to my understanding). In this case the CM axion is a purely longitudinal magnon. The longitudinal case does not have the simple Heisenberg interpretation or Kittel splitting of FKMH.', '    Can the present treatment be extended to this case of a longitudinal CM axion?', '    \\\\textbf{Reply}:     %%     We agree that the Fe-doped BiSe3 is different from the FKMH model. To our understanding, the axion as the longitudinal magnon in the Fe-doped BiSe3 is not simply expressed by the magnon creation/annihilation operator (at least at the linear level). Thus we think that some extended formalism is required to describe the CM axion in the Fe-doped BiSe3, although we have not found it.     %%', '    \\\\item Eq. 5.11 is formally divergent when $m_a=m_m$. Finite linewidth of the magnon regulates this divergence and leads to a Lorentzian resonance.', '    Instead the authors consider the approach to steady state up to the axion or magnon coherence time $\\\\tau$. I think a better approach when $Q_m<10^6$ ($Q_m$ is the magnon quality factor) is to integrate over the lineshape (as in a cavity haloscope), while $Q_m >10^6$ (corresponding to $\\\\tau_a < \\\\tau_m$ in 5.16) seems very optimistic.', '    I think this is the largest assumption made in the dark matter projection limits and needs far greater justification and discussion.', '    Simply put: the authors must justify their choice to take $\\\\tau_m > \\\\tau_a$', '    \\\\textbf{Reply}:     %%     First, Eq.(5.11) leads to $a_1(t) \\\\propto t$ for $m_a=m_m$ as shown in (5.12), if one carefully takes the limit $m_m\\\\to m_a$. Thus, there is no divergent behavior in Eq.(5.11) as far as the operation time is finite.     Including a magnon line width through the imaginary part of $m_m$ has the same effect as cutting the time $t$ with the magnon lifetime. Thus the effect of magnon width can be taken into account by considering a general value of $Q=Q_m$.', '    The actual value of $Q_m$ is difficult to identify, since we are using a toy model (FKMH model) and there is no real experiment so far in order to measure the magnon width.     In the original draft, $\\\\tau_a < \\\\tau_m$ is assumed just as an illustration of an optimistic setup.     In the revised manuscript we added the results with different choices of the quality factors $Q=10^3$ and $Q=10^4$ in Figs. 1 and 2, which show prospects for more realistic setups.     %%', '    \\\\item It is stated that CM axion mixing to the polariton is small. How can this be justified?', '    In the Fe-doped Bismuth Selenide case [39] ([41] in the revised draft) the mixing is large, and indeed in [37] ([39] in the revised draft) and in the present work the axion dark matter coupling is driven by this mixing, i.e. via the induced electric field.', '    To answer this: For the considered material parameters (CM axion decay constant, magnon mass) what is the effective $b$ parameter and ratio $b/m$ (see \\\\sout{[39]} [41])? If this ratio is small, then indeed the polariton mixing could possibly be neglected at leading order. However, $b/m$ effectively sets the amplitude of the driving term in the current treatment, so it is not clear that small $b/m$ is in any way advantageous.', '    Compared to \\\\sout{[37] and [72]} [39] and [74] the present work considers the axion-induced E-field as an external source and ignores the three way mixing axion DM - E-field - CM axion. The neglected mixing affects the dispersion relations, particularly at high applied $B$ field.', '    Is considering $E_0$ as a source field consistent in the perturbative expansion?', '    The authors should consider this mixing in more detail.', '    Going further, this may also need the assumption of uniform $E\\\\cdot B$ to be revised, since finite momentum (and momentum conservation) and material size are important factors in the mixing.  The uniform case considered at present is equivalent to considering only the free space resonance as in \\\\sout{[37]} [39] (see also minor comment below).', '    \\\\textbf{Reply}:     %%     For our set up, the $b$ parameter can be evaluated as     L3N00000001     which is much smaller than the assumed value $m\\\\sim 1\\\\,\\\\mathrm{meV}$ with a moderate choice of $|D| \\\\sim (u_{\\\\vec{0}}-v_{\\\\vec{0}}) \\\\sim O(1)$.     Thus, we confirm that CM axion mixing to the polariton is small and the effects of mixing on dispertion relations are negligible.     Also, it can be checked from Eqs. (5.14) and (5.29) that the small $b$ parameter works as a suppression factor to the signal rate $dN_{\\\\text{signal}} / dt$, which is proportional to $(b/m)^2$.     To achieve this conslusion, we assumed that the effect of the magnetic field and mixing are neglected so that the frequency of a magnon mode $\\\\omega_{\\\\vec{0}}$ can be used to approximate the mass of the axionic polariton.     %%', '    \\\\item It is stated “We do not discuss in detail the detection method of generated magnons in this paper; they might be observed through the conversion into photons at the boundary of the material.\" This conversion was shown explicitly in the paper appearing at the same time, \\\\sout{[72]} [74]. However, conversion requires the polariton E component to satisfy the boundary conditions for conversion. So I think that photon counting SNR cannot be consistently used if polariton mixing (above) is ignored.', '    \\\\textbf{Reply}:     %%     We agree that it is difficult to use the single photon counters to detect condensed matter axion when its mixing with photon is negligibly small.     The noise rate $dN_{\\\\text{noise}}/dt \\\\sim 10^{-3}\\\\,\\\\mathrm{s}^{-1}$ used in our draft is just an assumption to demonstrate the sensitivity reach in the DM parameter space.     We modified the corresponding paragraph and made this point clear.     %%', '    \\\\item The half filling Hubbard model at large $U$ is taken to be an antiferromagnetic insluator. Can finite conductance be included in the model? This was found to be a major issue in \\\\sout{[72]} [74], but perhaps the present case with low polariton mixing is less affected by conductance.', '    Is the Fermi level guaranteed to lie in the gap of the bulk insulator FKMH model?', '    \\\\textbf{Reply}:     %%     In the setup of Ref.[72] (Ref.[74] in the revised draft), the CM axion is converted to electric field (or the polariton) and hence the conductance was important. We do not necessarily assume such a setup. ', '   As far as the half-filling case is considered, the Fermi energy lies at the bulk gap since the number of states of $E<0$ and $E>0$ are the same (Eq.(4.10)). If the DM axion mass is smaller than the gap energy, it is safely regarded as a bulk insulator. On the other hand, if the DM axion mass is larger than the gap, there could be a transition from the occupied states to the empty states: such an idea was discussed in Ref. [64].     %%', '    \\\\item  CM axion parameters', '    * What is the relationship between the CM axion decay constant in footnote 7 and the related quantity computed from the electron band energies in [39]? The present model seems simpler, but maybe there are $O(1)$ constants omitted or assumed? A translation/comparison would help.', '     \\\\textbf{Reply}:     %%     The decay constant $f_{\\\\rm CM}$ is defined as a suppression scale of the effective Hamiltonian of the canonically normalized scalar fields (see the equation in revised footnote 7).  In footnote 7, we have given an explicit definition of the decay constant.  In our previous manuscript, we have neglected an $O(1)$ constant in estimating $f_{\\\\rm CM}$, which is now included.  Comparison of our $f_{\\\\rm CM}$ with the parameters in [39] is not straightforward because there show up two CM axions in the present case, i.e., the $\\\\alpha$- and $\\\\beta$-modes.  From the relation between $\\\\delta\\\\theta$ and the canonically normalized field in [39], we obtain $f_{\\\\mathrm{CM}}^2 \\\\sim O(g^2 J)$.  Notice that, for the above argument, we assumed that the effect of the magnetic field and mixing are neglected so that the frequency of a magnon mode $\\\\omega_{\\\\vec{0}}$ can be used to approximate the mass of the axionic polariton.', '%\\\\rem{ %    We have added the $O(1)$ coefficient of $f_{\\\\mathrm{CM}}$ in footnote 7 that was omitted in the original draft to clarify the definition. %    In this definition, the combination of parameters $g^2 J$ appeared in \\\\sout{[39]} [41] is related to the decay constant as $f_{\\\\mathrm{CM}}^2 = g^2 J$. %    To derive this relationship, we assumed that the effect of the magnetic field and mixing are neglected so that the frequency of a magnon mode $\\\\omega_{\\\\vec{0}}$ can be used to approximate the mass of the axionic polariton. %    To derive it, however, one should note that the axion mass of \\\\sout{[39]} [41] and ours are qualitatively different, as explained in the reply below.} %    \\\\rem{Should we show the detailed derivation in the draft?}', '    * What is the relation between the CM axion mass in the present work,and that considered in the other works in the field, namely \\\\sout{[39], [37], [72],} [41], [39], [74], and the recent paper https://arxiv.org/abs/2103.02848', '    \\\\textbf{Reply}:     %%     (Refs.[37],[39],[72] in old version correspond to [39],[41],[74] in the modified version. Below we use the latter.)     The axion mass of Refs.[39] and [74] is both based on Ref.[41] in the Fe-doped BiSe3 model, which are also reviewed in Ref.[42]. In these works the axion mass is calculated through the one-loop effect (the so-called random phase approximation) with the Dirac electron running in the loop. However, the recent paper 2103.02848 pointed out that the calculation in those works have missed the tree level axion mass term and also the sign of the one-loop axion mass is actually opposite (tachyonic). Thus the axion mass calculations in Refs.[39],[41],[74] are questionable according to 2103.02848. ', '    On the other hand, in our present work, we do not rely on those previous works for the axion mass calculation. Since the CM axion is simply related to the magnon in the FKMH model, we can use the well-known dispersion relation of the anti-ferromagnetic magnon of the Heisenberg model.     %%', '    * The authors should have a clear layout in Section 5 of the relevant parameters and the chosen values, and a comparison to other theoretical works and experimental measurements. For example, Eq. \\\\sout{5.17} 5.16 and also the values for $V_{\\\\mathrm{unit}}$ have no references.', '    Reference to real materials and experimental measurements would also greatly help the justification of choosing long magnon coherence times (see above).', '    \\\\textbf{Reply}:     %%     Our discussion is based on the FKMH model, and hence there is no corresponding real material known so far. However, we are using typical reference values for model parameters. For example, $V_{\\\\rm unit}\\\\sim (0.3\\\\,{\\\\rm keV})^{-3}$ is taken from that of Bi$_2$Se$_3$ (although it is not described by the FKMH model), $V_{\\\\rm unit}\\\\simeq 440\\\\,{\\\\rm \\\\AA}^3$~[74].', '    The CM axion mass expression (5.16) is based on (2.12). The second term is the Larmor frequency and the reference value of the first term is also taken from that of Fe-doped Bi$_2$Se$_3$~[39]. We added explanation below Eq.(5.16) to make this point clear.     %%', '    \\\\item Minor comments:', '    * Earlier work on magnons for axion detection, including an experiment ran in the 90’s, and proposals to use antiferromagnets, include: https://inspirehep.net/literature/406693, https://inspirehep.net/literature/306742', '    \\\\textbf{Reply}:     %%     We cited these papers at the end of the first paragraph of the introduction.     %%', '    * It is not clear to me what the physical significance of the dot dashed curves in Fig. 1 is. What does it mean that a mode can have $u-v=1$? Is this expected or not?', '    \\\\textbf{Reply}:     %%     The value of $u-v$ should strongly depend on the material, but $|u-v|\\\\sim \\\\mathcal O(1)$ is more or less natural, so we present it just for reference partly because $|u-v|=10$ may be too optimistic.         %%', '    * A large material volume $10\\\\,\\\\mathrm{cm}^3$ is assumed. Can the authors comment on the possible realisation/geometry of this? For example, QUAX use many spheres of order 1 mm3, while [72] propose large area thin disks. Does the present treatment suggest a preferred geometry? I think it cannot, since the finite momentum effects are neglected and only the free space resonance is considered (as in [37]).', '    \\\\textbf{Reply}:     %%     Within our treatment, the geometry of the material is not very relevant as far as it is much smaller than the DM axion de-Broglie wavelength. For example, $10^3$ sets of (1cm)$^3$ material gives the same sensitivity as the one (10cm)$^3$ sample.      %%', '    * The conclusions seem rushed', '    \\\\textbf{Reply}:     %%     We newly added a paragraph at the beginning of Sec.6 and also added several extended discussions.     %%', '']\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'content' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/c0/ngmx57px0yq0jz7b0wx44lqw0000gn/T/ipykernel_83589/2831222530.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlatex_ja\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslateTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtexdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/c0/ngmx57px0yq0jz7b0wx44lqw0000gn/T/ipykernel_83589/775485476.py\u001b[0m in \u001b[0;36mtranslateTree\u001b[0;34m(tree, texdict, layer, doc)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mtexdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'L'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'N'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'{:008}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslateTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtexdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m# convert back tags into original formula\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/c0/ngmx57px0yq0jz7b0wx44lqw0000gn/T/ipykernel_83589/775485476.py\u001b[0m in \u001b[0;36mtranslateTree\u001b[0;34m(tree, texdict, layer, doc)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mtexdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'L'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'N'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'{:008}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslateTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtexdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m# convert back tags into original formula\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/c0/ngmx57px0yq0jz7b0wx44lqw0000gn/T/ipykernel_83589/775485476.py\u001b[0m in \u001b[0;36mtranslateTree\u001b[0;34m(tree, texdict, layer, doc)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mparas_ja\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mlatexParse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparas_ja\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;31m#         paras_ja = [translateParagraph(p) for p in paras]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/c0/ngmx57px0yq0jz7b0wx44lqw0000gn/T/ipykernel_83589/775485476.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mparas_ja\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mlatexParse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparas_ja\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;31m#         paras_ja = [translateParagraph(p) for p in paras]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/c0/ngmx57px0yq0jz7b0wx44lqw0000gn/T/ipykernel_83589/3844362087.py\u001b[0m in \u001b[0;36mlatexParse\u001b[0;34m(par)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLatexWalker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0mnodelist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_latex_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtranslateAllContents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodelist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/c0/ngmx57px0yq0jz7b0wx44lqw0000gn/T/ipykernel_83589/559952509.py\u001b[0m in \u001b[0;36mtranslateAllContents\u001b[0;34m(nl)\u001b[0m\n\u001b[1;32m     20\u001b[0m                     \u001b[0melem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodeargd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margnlist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0melem\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                         \u001b[0mtranslateContent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/c0/ngmx57px0yq0jz7b0wx44lqw0000gn/T/ipykernel_83589/2740288951.py\u001b[0m in \u001b[0;36mtranslateContent\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtranslateContent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#     _, content = translateOneLevel(node)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodelist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mLatexCharsNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsing_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'content' is not defined"
     ]
    }
   ],
   "source": [
    "latex_ja = translateTree(tree, texdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppc.copy(clipboard)\n",
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
